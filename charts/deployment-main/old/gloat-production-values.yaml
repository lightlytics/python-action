# Default values for dan-deployment.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# TODO: proper globals
# TODO: separate container ports and service ports

autoscaling:
  minReplicas: 1
  maxReplicas: 5
  metrics:
    resource:
      averageUtilization: 80
service:
  default_type: ClusterIP
  default_protocol: TCP
  default_port: 80
  default_traget_port: 80

deployment:
  env:
    #    todo(zeev): "Environment" var is deprecated, remove it later
    Environment: Prod
    ENV: Prod
    DOMAIN_NAME: lightlytics.com
    SES_CONFIGURATION_SET: lightlytics_configuration_set
    LOGLEVEL: INFO
    AWS_ACCOUNT: "624907860825"
    S3_PUBLIC_CFT_BUCKET_NAME: prod-lightlytics-public-cloudformation
    S3_BUCKET_NAME: prod-lightlytics-public-cloudformation
    KAFKA_BROKERS: "b-1.gloat-kafka-cluster.dl7541.c6.kafka.us-east-1.amazonaws.com:9092,b-2.gloat-kafka-cluster.dl7541.c6.kafka.us-east-1.amazonaws.com:9092"
    CUSTOMERS_MS_URL: http://customers
    CLIENT_MONGODB_HOST: gloat-mongo-primary.lightlytics.com,gloat-mongodb-secondary-0.lightlytics.com,gloat-mongodb-secondary-1.lightlytics.com
    CLIENT_MONGODB_PORT: 27017,27017,27017
    CLIENT_MONGODB_OPTIONS: /?replicaSet=s0&readPreference=secondaryPreferred&retryWrites=false
    NEO4J_CORE_SERVERS: '["10.0.0.163", "10.0.1.171", "10.0.1.183"]'
    NEO4J_PORT: 7687
    NEO4J_DB_NAME: neo4j
    SLACK_CLIENT_ID: 903209810486.1615283763813
    SLACK_CLIENT_SECRET: 3d654100f5233ad120baf67da771c318
    S3_MONGO_BACKUPS_BUCKET_NAME: prod-lightlytics-mongodb-backups


  imagepullPolicy: Always
  buildNumber: latest
  branchName: master
  ReplicaCount: 1
  hpa_enable: "yes"
  resources:
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 1024Mi
      cpu: 800m

hooks:
  onboarding:
    imageName: tasks
    hook: post-install
    command:
      - /usr/local/bin/python
      - main.py
      - --function
      - onboarding

  index-lightlytics:
    imageName: tasks
    hook: post-install
    command:
      - /usr/local/bin/python
      - main.py
      - --function
      - index_lightlytics

external_secrets:
  access-token-public-key:
    key: access_token_public_key_secret
    values:
      - public_key
  access-token-private-key:
    key: access_token_private_key_secret
    values:
      - private_key
  mongo-cred:
    key: mongo_top_secret
    values:
      - username
      - password
  neo4j-cred:
    key: neo4j_server_top_secret
    values:
      - username
      - password
  support-cred:
    key: lightlytics_support_user
    values:
      - username
      - password

secrets:
  SECRET_MONGO_PASSWORD:
    secret_name: mongo-cred
    secret_key: password

  SECRET_MONGO_USERNAME:
    secret_name: mongo-cred
    secret_key: username

  SECRET_NEO4J_PASSWORD:
    secret_name: neo4j-cred
    secret_key: password

  SECRET_NEO4J_USERNAME:
    secret_name: neo4j-cred
    secret_key: username

  SECRET_LIGHTLYTICS_SUPPORT_USERNAME:
    secret_name: support-cred
    secret_key: username

  SECRET_LIGHTLYTICS_SUPPORT_PASSWORD:
    secret_name: support-cred
    secret_key: password

cronjob:
  scan-all:
    imageName: tasks
    schedule: "0 0 * * *"
    command:
      - /usr/local/bin/python
      - main.py
      - --function
      - scan_all
  periodic-scan:
    imageName: tasks
    schedule: "*/20 * * * *"
    command:
      - /usr/local/bin/python
      - main.py
      - --function
      - periodic_scan
  backup-mongodb:
    imageName: tasks
    schedule: "0 3 * * *"
    command:
      - /usr/local/bin/python
      - main.py
      - --function
      - backup_mongodb
    env:
      AWS_ROLE_ARN: arn:aws:iam::624907860825:role/gloat-cronjob_mongo_backup_role
      AWS_WEB_IDENTITY_TOKEN_FILE: /var/run/secrets/eks.amazonaws.com/serviceaccount/token
    serviceAccount:
      serviceAccountName: tasks-mongodb-sa
      annotations:
        eks.amazonaws.com/role-arn: arn:aws:iam::624907860825:role/gloat-cronjob_mongo_backup_role
    volumeMounts:
      aws-iam-token:
        mountPath: /var/run/secrets/eks.amazonaws.com/serviceaccount

lightlytics_ms:
  customers:
    service:
      targetPort: 8500
    deployment:
      env:
        MSName: customers
        AWS_ROLE_ARN: arn:aws:iam::624907860825:role/gloat-ms_customers_role
        AWS_WEB_IDENTITY_TOKEN_FILE: /var/run/secrets/eks.amazonaws.com/serviceaccount/token
      secrets:
        SECRET_ACCESS_TOKEN_PRIVATE_KEY:
          secret_name: access-token-private-key
          secret_key: private_key
        SECRET_ACCESS_TOKEN_PUBLIC_KEY:
          secret_name: access-token-public-key
          secret_key: public_key
      volumeMounts:
        aws-iam-token:
          mountPath: /var/run/secrets/eks.amazonaws.com/serviceaccount
    serviceAccount:
      serviceAccountName: account-manager-customers
      annotations:
        eks.amazonaws.com/role-arn: arn:aws:iam::624907860825:role/gloat-ms_customers_role
  account:
    service:
      targetPort: 8000
    deployment:
      env:
        AWS_ROLE_ARN: arn:aws:iam::624907860825:role/gloat-ms_account_role
        AWS_WEB_IDENTITY_TOKEN_FILE: /var/run/secrets/eks.amazonaws.com/serviceaccount/token
        MSName: account
      volumeMounts:
        aws-iam-token:
          mountPath: /var/run/secrets/eks.amazonaws.com/serviceaccount

    serviceAccount:
      serviceAccountName: account-manager-sa
      annotations:
        eks.amazonaws.com/role-arn: arn:aws:iam::624907860825:role/gloat-ms_account_role
  scan:
    service:
      targetPort: 3000
    deployment:
      hpa_enable: "no"
      pullPolicy: Always
      env:
        MSName: scan

  topology:
    service:
      targetPort: 5000
    deployment:
      env:
        MSName: topology

  alert:
    service:
      targetPort: 7000
    deployment:
      env:
        MSName: alert

  changes:
    service:
      targetPort: 2000
    deployment:
      hpa_enable: "no"
      env:
        MSName: changes
        AWS_ROLE_ARN: arn:aws:iam::624907860825:role/gloat-ms_changes_role
        AWS_WEB_IDENTITY_TOKEN_FILE: /var/run/secrets/eks.amazonaws.com/serviceaccount/token
      volumeMounts:
        aws-iam-token:
          mountPath: /var/run/secrets/eks.amazonaws.com/serviceaccount
      startupProbe:
        path: /changes/start
        failureThreshold: 30
        periodSeconds: 10
      livenessProbe:
        path: /changes/status
        failureThreshold: 3
        periodSeconds: 60
    serviceAccount:
      serviceAccountName: changes-sa
      annotations:
        eks.amazonaws.com/role-arn: arn:aws:iam::624907860825:role/gloat-ms_changes_role

  snapshot:
    service:
      targetPort: 4000
    deployment:
      env:
        MSName: snapshot
      livenessProbe:
        path: /snapshot/status
        failureThreshold: 3
        periodSeconds: 60
      resources:
        requests:
          memory: 2048Mi
          cpu: 1000m
        limits:
          memory: 4096Mi
          cpu: 2000m


  analyzer:
    service:
      targetPort: 6000
    deployment:
      env:
        MSName: analyzer
      resources:
        requests:
          memory: 2048Mi
          cpu: 1000m
        limits:
          memory: 4096Mi
          cpu: 2000m


  terraform:
    service:
      targetPort: 10000
    deployment:
      env:
        MSName: terraform

  configurationfiles:
    service:
      targetPort: 9000
    deployment:
      env:
        MSName: configurationfiles

  front-gate:
    service:
      type: ClusterIP
      targetPort: 1000
    deployment:
      hpa_enable: "no"
      env:
        MSName: front_gate
        NODE_ENV: production

  front-end:
    # TODO: move to CDN (cloudfront)
    service:
      type: ClusterIP
      targetPort: 80
    deployment:
      hpa_enable: "no"
      env:
        MSName: front_end

  collection-producer:
    imageName: collection
    service:
      type: LoadBalancer
      targetPort: 4242
      ssl_enabled: true
      annotations:
        external-dns.alpha.kubernetes.io/ttl: "10"
        external-dns.alpha.kubernetes.io/hostname: -kafka-producer.lightlytics.com
        service.beta.kubernetes.io/aws-load-balancer-type: nlb
        service.beta.kubernetes.io/aws-load-balancer-internal: "true"
        service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:us-east-1:624907860825:certificate/dbb51e1f-195f-4227-affd-93033f44069a
        service.beta.kubernetes.io/aws-load-balancer-ssl-ports: "443,8443"
    deployment:
      command: "/producer"
      hpa_enable: "no"
      env:
        MSName: collection-producer

  collection-consumer:
    imageName: collection
    deployment:
      command: "/consumer"
      # hpa = auto scaler
      hpa_enable: "no"
      env:
        MSName: collection-consumer

ingress:
  urlTypes:
    - ""
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=1200
    #    this is a health check to make sure that the pod is alive in order to include it at the ALB routing level.
    #    todo:  we need to move this to the service level, maybe consider different health for this role.
    alb.ingress.kubernetes.io/healthcheck-path: /healthcheck
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: '300'


mongodb:
  mongodbUsername: admin
  mongodbDatabase: lightlytics
  service:
    name: mongodb
  enabled: false

neo4j:
  core:
    service:
      name: neo4j
    standalone: true
  acceptLicenseAgreement: "yes"
  enabled: false
